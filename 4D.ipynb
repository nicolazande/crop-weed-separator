{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5FnwOggnFIl"
   },
   "outputs": [],
   "source": [
    "# ---------- visualizzo piu output a schermo insieme ------------------------------\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "#-------------------------- scelgo se usare CPU o GPU -----------------------------\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "cwd = os.getcwd()\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # CPU = -1 , GPU = 0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "elif cpus:\n",
    "    try:\n",
    "        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\n",
    "        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "#---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- scelta parametri -----------------------------------------\n",
    "img_h = 192\n",
    "img_w = 256\n",
    "N_classes = 4\n",
    "\n",
    "# scala a cui va ridotta una singola patch dell'immagine\n",
    "LUT_scale = {\"BipbipHaricot\": 2,\n",
    "             \"BipbipMais\": 4,\n",
    "             \"PeadHaricot\": 1,\n",
    "             \"PeadMais\": 1,\n",
    "             \"RoseauHaricot\": 1,\n",
    "             \"RoseauMais\": 1,\n",
    "             \"WeedelecHaricot\": 4,\n",
    "             \"WeedelecMais\": 4}\n",
    "\n",
    "# immagini come multipli di patch standard 192x256\n",
    "TEAM_SIZES = {\"Bipbip\": [(2048, 1536), 8],  # sacale = 1 + scale = 2\n",
    "                  \"Pead\": [(3072, 2304), 12],\n",
    "                  \"Roseau\": [(1280, 960), 5],\n",
    "                  \"Weedelec\": [(5120, 3840), 20]}\n",
    "\n",
    "BS = 3\n",
    "split = 0.8\n",
    "EP = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# preparo le patches dei diversi team / crop dividendo immagini e maschere del training set escludendo patches completamente nere\n",
    "\n",
    "prepare_patches = True\n",
    "\n",
    "if prepare_patches:\n",
    "    \n",
    "    teams = [\"Pead\"] # <-- scegli team\n",
    "    crops = [\"Haricot\"] # <-- scegli crop\n",
    "    \n",
    "    PSI = 0.95 # <-- scegli quali patche scartare in base a percentuale massima background\n",
    "\n",
    "    source_dir = os.path.join(cwd,'Development_Dataset', 'Training')\n",
    "    patch_dir = os.path.join(cwd, 'Patches')\n",
    "    if not os.path.exists(patch_dir):\n",
    "        os.makedirs(patch_dir)\n",
    "\n",
    "    for team in teams:\n",
    "        for crop in crops:\n",
    "            scale = LUT_scale[team + crop]\n",
    "            filenames = os.listdir(os.path.join(source_dir, team, crop, 'Images'))\n",
    "            filenames = [f.split('.')[0] for f in filenames]\n",
    "\n",
    "            for curr_filename in filenames:\n",
    "                \n",
    "                if os.path.isfile(os.path.join(source_dir, team, crop, 'Images', curr_filename + '.png')):\n",
    "                    img = np.array(Image.open(os.path.join(source_dir, team, crop, 'Images', curr_filename + '.png')).resize(TEAM_SIZES[team][0]))\n",
    "                    ext = \".png\"\n",
    "                else:\n",
    "                    img = np.array(Image.open(os.path.join(source_dir, team, crop, 'Images', curr_filename + '.jpg')).resize(TEAM_SIZES[team][0]))\n",
    "                    ext = \".jpg\"\n",
    "                    \n",
    "                mask = np.array(Image.open(os.path.join(source_dir, team, crop, 'Masks', curr_filename + '.png')).resize(TEAM_SIZES[team][0]))\n",
    "               \n",
    "                curr_dir = os.path.join(patch_dir, team, crop)\n",
    "                if not os.path.exists(curr_dir):\n",
    "                    os.makedirs(curr_dir)\n",
    "                    os.makedirs(os.path.join(curr_dir, \"Images\"))\n",
    "                    os.makedirs(os.path.join(curr_dir, \"Masks\"))\n",
    "\n",
    "                #--------- salvo patches maschere e immagini ---------------------------------------------------\n",
    "                for i in range(int(TEAM_SIZES[team][1]/scale)):\n",
    "                    for j in range(int(TEAM_SIZES[team][1]/scale)):\n",
    "                        pixels = mask[i*img_h*scale:(i+1)*img_h*scale,j*img_w*scale:(j+1)*img_w*scale,:]\n",
    "                        \n",
    "                        if tf.reduce_sum(tf.cast(np.all(pixels == [254, 124, 18], axis=-1),tf.float32) + tf.cast(np.all(pixels == [0, 0, 0], axis=-1),tf.float32)) <= img_h*scale*img_w*scale*PSI:\n",
    "                            \n",
    "                            #maschera\n",
    "                            curr_patch_mask = Image.fromarray(pixels, 'RGB')\n",
    "                            curr_patch_mask.save(os.path.join(curr_dir, 'Masks', curr_filename + \"_\" + str(i) + \"_\" + str(j) + \"_\" + str(scale) + \".png\"))\n",
    "                            \n",
    "                            #immagine\n",
    "                            curr_patch_img = Image.fromarray(img[i*img_h*scale:(i+1)*img_h*scale,j*img_w*scale:(j+1)*img_w*scale,:], 'RGB')\n",
    "                            curr_patch_img.save(os.path.join(curr_dir, 'Images', curr_filename + \"_\" + str(i) + \"_\" + str(j) + \"_\" + str(scale) + ext))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4N88wG50nFI3"
   },
   "outputs": [],
   "source": [
    "#--------------- creo i data generator -------------------------------------\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "if apply_data_augmentation:\n",
    "    #immagini\n",
    "    img_data_gen = ImageDataGenerator(rotation_range=30,\n",
    "                                      width_shift_range=0.1,\n",
    "                                      height_shift_range=0.1,\n",
    "                                      #brightness_range=[1,1.8],\n",
    "                                      zoom_range=0.3,\n",
    "                                      shear_range=10,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=True,\n",
    "                                      fill_mode='reflect')\n",
    "    #maschere\n",
    "    mask_data_gen = ImageDataGenerator(rotation_range=30,\n",
    "                                      width_shift_range=0.1,\n",
    "                                      height_shift_range=0.1,\n",
    "                                      #brightness_range=[1,1.8],\n",
    "                                      zoom_range=0.3,\n",
    "                                      shear_range=10,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=True,\n",
    "                                      fill_mode='reflect')\n",
    "\n",
    "else:\n",
    "    img_data_gen = ImageDataGenerator(fill_mode='reflect')\n",
    "\n",
    "    mask_data_gen = ImageDataGenerator(fill_mode='reflect')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsieZk4aKhm6"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "    \n",
    "    # costruttore: \n",
    "    def __init__(self, dataset_dir, team, crop, which_subset, subset_filenames, img_generator=None, mask_generator=None, \n",
    "               preprocessing_function=None, out_shape=[img_w,img_h]):\n",
    "        \n",
    "        self.which_subset = which_subset\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.subset_filenames = subset_filenames\n",
    "        self.out_shape = out_shape\n",
    "        self.img_generator = img_generator\n",
    "        self.mask_generator = mask_generator\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        self.team = team\n",
    "        self.crop = crop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        curr_filename = self.subset_filenames[index]\n",
    "        \n",
    "        if os.path.isfile(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.png')):\n",
    "            img = Image.open(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.png'))\n",
    "        else:\n",
    "            img = Image.open(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.jpg'))\n",
    "            \n",
    "        mask = Image.open(os.path.join(dataset_dir, team, crop, 'Masks', curr_filename + '.png'))\n",
    "        \n",
    "        img = img.resize(self.out_shape)\n",
    "        mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
    "\n",
    "        img_arr = np.array(img)\n",
    "        mask_arr = np.array(mask)\n",
    "        # uso one-hot encoding con 4 classi\n",
    "        new_mask_arr = np.zeros((mask_arr.shape[0], mask_arr.shape[1], 4))\n",
    "        \n",
    "        # trasfotmazione maschera e immagine\n",
    "        if self.which_subset == 'training':\n",
    "            if self.img_generator is not None and self.mask_generator is not None:\n",
    "                img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
    "                mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n",
    "                img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
    "                mask_arr = np.uint8(self.mask_generator.apply_transform(mask_arr, mask_t))\n",
    "        \n",
    "        #tengo separati background e orange label\n",
    "        new_mask_arr[np.where(np.all(mask_arr == [254, 124, 18], axis=-1))] = [0, 1, 0, 0] #background\n",
    "        new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = [0, 0, 1, 0] #crop\n",
    "        new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = [0, 0, 0, 1] #weed\n",
    "        new_mask_arr[np.where(np.all(new_mask_arr == [0, 0, 0, 0], axis=-1))] = [1, 0, 0, 0] #backgroung\n",
    "        \n",
    "        if self.preprocessing_function is not None:\n",
    "            img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "        return img_arr, np.float32(new_mask_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "#---------- funzione per random split (train/validation) -------------\n",
    "def random_pick(filenames, percent):\n",
    "    percent = np.clip(percent, 0, 1)\n",
    "    subset = []\n",
    "    n = int(percent*len(filenames))\n",
    "    for i in range(0, n):\n",
    "        index = np.random.randint(0, len(filenames))\n",
    "        subset.append(filenames[index])\n",
    "        del(filenames[index])        \n",
    "    return subset\n",
    "\n",
    "#-------- scegli dataset -----------------------------------------\n",
    "dataset_dir = os.path.join(cwd,'Patches')\n",
    "team = 'Pead'\n",
    "crop = 'Haricot'\n",
    "#-----------------------------------------------------------------\n",
    "imm_source = os.path.join(dataset_dir, team, crop, 'Images')\n",
    "subset_filenames = os.listdir(imm_source)\n",
    "subset_filenames = [f.split('.')[0] for f in subset_filenames]\n",
    "\n",
    "#subset_filenames = random_pick(subset_filenames, 0.3)\n",
    "print(\"tot_imgs = \" + str(len(subset_filenames)))\n",
    "\n",
    "# seleziono immagini training\n",
    "train_imm = random_pick(subset_filenames, split)\n",
    "print(\"training_imgs = \" + str(len(train_imm)))\n",
    "\n",
    "# seleziono immagini training\n",
    "valid_imm = []\n",
    "for imm in subset_filenames:\n",
    "    if imm not in train_imm:\n",
    "        valid_imm.append(imm)        \n",
    "\n",
    "print(\"validation_imgs = \" + str(len(valid_imm)))\n",
    "\n",
    "\n",
    "\n",
    "#-------- definisco datasets ----------------------------------------\n",
    "dataset = CustomDataset(dataset_dir = dataset_dir,\n",
    "                        team = team,\n",
    "                        crop = crop,\n",
    "                        which_subset = 'training',\n",
    "                        subset_filenames = train_imm,\n",
    "                        img_generator = img_data_gen,\n",
    "                        mask_generator = mask_data_gen,\n",
    "                        preprocessing_function = preprocess_input)\n",
    "\n",
    "dataset_valid = CustomDataset(dataset_dir = dataset_dir,\n",
    "                              team = team,\n",
    "                              crop = crop,\n",
    "                              which_subset = 'validation',\n",
    "                              subset_filenames = valid_imm,\n",
    "                              preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usz5SKPeQrOE"
   },
   "outputs": [],
   "source": [
    "#---------- train dataset -----------------------------------------------------------------\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 4]))\n",
    "train_dataset = train_dataset.batch(BS)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "#------------ valid dataset ---------------------------------------------------------------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 4]))\n",
    "valid_dataset = valid_dataset.batch(BS)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvsdiF0TFTbt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "# modello --> U-net like: [256, 128, 64, 32] migliore per trial and error\n",
    "def get_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x\n",
    "\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        residual = tf.keras.layers.Conv2D(filters, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
    "        x = tf.keras.layers.add([x, residual])\n",
    "        previous_block_activation = x\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.UpSampling2D(2)(x)\n",
    "\n",
    "        residual = tf.keras.layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = tf.keras.layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = tf.keras.layers.add([x, residual])\n",
    "        previous_block_activation = x\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k97OK6CRnFJS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-------------- creo il modello ----------------------------------------------------------------\n",
    "teams = [\"Bipbip\", \"Pead\", \"Roseau\", \"Weedelec\"]\n",
    "crops = [\"Haricot\", \"Mais\"]\n",
    "\n",
    "model = get_model((img_h, img_w, 3), N_classes)\n",
    "\n",
    "#carico i pesi\n",
    "load_weights = True\n",
    "if load_weights:\n",
    "    model_name = teams[0] + crops[0] #<-- scegli quale TEAM/CROP caricare\n",
    "    model_dir = os.path.join(cwd, 'weights_4D', model_name)\n",
    "    model.load_weights(os.path.join(model_dir, model_name))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ IoU(intersect over union): metodo per valutare la performance --------------------\n",
    "# non peso IoU per poter visualizzare valore verosimile\n",
    "def meanIoU(y_true, y_pred):\n",
    "    per_class_iou = []\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    # non includo ne orange labels ne background\n",
    "    for i in range(2,N_classes):       \n",
    "        intersection = tf.reduce_sum(y_true[:,:,i] * y_pred[:,:,i])\n",
    "        union = tf.reduce_sum(y_true[:,:,i]) + tf.reduce_sum(y_pred[:,:,i]) - intersection\n",
    "        iou = ((intersection + 1e-7) / (union + 1e-7))\n",
    "        per_class_iou.append(iou)\n",
    "\n",
    "    return tf.reduce_mean(per_class_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- custom loss --> weighted_pixelwise_crossentropy ------------------------------\n",
    "def weighted_pixelwise_crossentropy(class_weights):\n",
    "    _EPSILON = 1e-7\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = tf.convert_to_tensor(_EPSILON, y_pred.dtype.base_dtype)\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        return -tf.reduce_sum(tf.multiply(y_true * tf.math.log(y_pred), class_weights))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- custom loss --> diagonal_pixelwise_crossentropy ------------------------------\n",
    "def diagonal_pixelwise_crossentropy(class_weights):\n",
    "    _EPSILON = 1e-7\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = tf.convert_to_tensor(_EPSILON, y_pred.dtype.base_dtype)        \n",
    "        per_class_loss = []\n",
    "        for i in range(0,N_classes):            \n",
    "            slice_pred = tf.clip_by_value(y_pred[:,:,i], epsilon, 1. - epsilon)\n",
    "            slice_true = y_true[:,:,i]\n",
    "            tmp = -tf.reduce_sum(tf.multiply(slice_true * tf.math.log(slice_pred), class_weights[i]))\n",
    "            per_class_loss.append(tmp)            \n",
    "        return tf.reduce_mean(per_class_loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- custom loss --> IoU_crossentropy ------------------------------\n",
    "def IoU_crossentropy(class_weights):\n",
    "    \n",
    "    _EPSILON = 1e-9\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = tf.convert_to_tensor(_EPSILON, y_pred.dtype.base_dtype)\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        intersection = -tf.reduce_sum(y_true * tf.math.log(y_pred))\n",
    "        union = tf.clip_by_value(tf.reduce_sum(y_true) + tf.reduce_sum(y_pred), epsilon, float(\"inf\"))\n",
    "        return tf.reduce_mean(tf.multiply(intersection / union, class_weights))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- custom loss --> UoI_crossentropy ------------------------------\n",
    "def UoI_loss(class_weights):\n",
    "    \n",
    "    _EPSILON = 1e-9\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = tf.convert_to_tensor(_EPSILON, y_pred.dtype.base_dtype)\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        intersection = tf.clip_by_value(tf.reduce_sum(y_true * y_pred), epsilon, float(\"inf\"))\n",
    "        union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "        return tf.reduce_mean(tf.multiply(union / intersection, class_weights))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- classe per cambiare lr ----------------------\n",
    "class CLR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, schedule):\n",
    "        super(CLR, self).__init__()\n",
    "        self.schedule = schedule\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('non hai settato lr')\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XiwaKZhnFJa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#---------------- definisco callbacks ------------------------------------\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "#--------------------------- lookup table per lr (standard)-------------\n",
    "LUT_STD = []\n",
    "#------------------- funzione per passare lr ---------------------------\n",
    "def get_lr_std(epoch, lr):\n",
    "    if epoch < LUT_STD[0][0]:\n",
    "        return LUT_STD[0][1]\n",
    "    elif epoch > LUT_STD[len(LUT_STD)-1][0]:\n",
    "        return LUT_STD[len(LUT_STD)-1][1]\n",
    "    for i in range(len(LUT_STD)):\n",
    "        if epoch == LUT_STD[i][0]:\n",
    "            print(\"\\nnuovo lr: \"+str(LUT_STD[i][1]))\n",
    "            return LUT_STD[i][1]\n",
    "    return lr\n",
    "\n",
    "callbacks.append(CLR(get_lr_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- one hot encoders ------------------------------------------------\n",
    "# [1, 0, 0, 0] = background\n",
    "# [0, 1, 0, 0]  = background\n",
    "# [0, 0, 1, 0]  = crop\n",
    "# [0, 0, 0, 1]  = weed\n",
    "\n",
    "class_weights = [1, 10, 180, 90]\n",
    "#----------------------------------------------------------------------------\n",
    "# allenate con loss nell'ordine: 1) --> 2) --> 3)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()  #1)\n",
    "#loss = IoU_crossentropy(class_weights)  #2)\n",
    "#loss = UoI_loss(class_weights)  #3)\n",
    "\n",
    "#loss= weighted_pixelwise_crossentropy(class_weights)  # per test)\n",
    "#loss = diagonal_pixelwise_crossentropy(class_weights)  #per test)\n",
    "\n",
    "metrics = ['accuracy', meanIoU]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- fitto modello ----------------------------------------\n",
    "EP = 20\n",
    "\n",
    "# <-- qua scegli i learning rate per epochs\n",
    "LUT_STD = [(0, 1e-3),\n",
    "           (10, 1e-4),\n",
    "           (20, 1e-6)]\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=EP,\n",
    "          steps_per_epoch=len(dataset),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(dataset_valid), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------- salvo pesi --------------------------------------------------\n",
    "save_weights = True\n",
    "\n",
    "if save_weights:\n",
    "    model_name = team + crop\n",
    "    model_dir = os.path.join(cwd, 'weights_4D')\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)    \n",
    "    model.save_weights(os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- funzioni per riscalare immagine ------------------------------------\n",
    "import scipy\n",
    "#---------- riscalo per target size (no interpolazione) -------------------\n",
    "def MAP(arr, X):\n",
    "    (w,h) = arr.shape\n",
    "    new_arr = np.zeros((X*w,X*h), dtype=arr.dtype)\n",
    "    for j in range(w):\n",
    "        for i in range(h):\n",
    "            new_arr[j*X:X*(j+1), i*X:X*(i+1)] = arr[j,i]\n",
    "            \n",
    "    return new_arr\n",
    "\n",
    "#------- zoom a target size (con bilinear interpolazione) ----------------\n",
    "def zoom_target(out_sigmoid, scale):\n",
    "    big_sigmoid = np.zeros((scale*out_sigmoid.shape[0], scale*out_sigmoid.shape[1], 3))\n",
    "    for i in range(out_sigmoid.shape[2]):\n",
    "        big_sigmoid[:,:,i] = scipy.ndimage.zoom(out_sigmoid[:,:,i], scale, order=3)\n",
    "    return tf.argmax(big_sigmoid, -1)\n",
    "\n",
    "#------- resize a target size (con bilinear interpolazione) --------------\n",
    "def resize_target(out_sigmoid, target_shape):\n",
    "    big_sigmoid = np.zeros((target_shape[0], target_shape[1], target_shape[2]), dtype=np.float32)\n",
    "    for i in range(out_sigmoid.shape[2]):\n",
    "        big_sigmoid[:,:,i] = np.array(Image.fromarray(out_sigmoid[:,:,i]).resize((target_shape[1], target_shape[0])))\n",
    "    return big_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- preparo per plottare ---------------------------------------------\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "item = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTO: IMMAGINE vs TRUE MASK vs PREDICTED MASK vs ZOOMED MASK\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(32, 32))\n",
    "ax[0].set_title('reconstructed image')\n",
    "ax[1].set_title('true mask')\n",
    "ax[2].set_title('predicted mask')\n",
    "ax[3].set_title('zoomed prediction')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "dataset_dir = os.path.join(cwd,'Development_Dataset', 'Training')\n",
    "teams = [\"Bipbip\", \"Pead\", \"Roseau\", \"Weedelec\"]\n",
    "crops = [\"Haricot\", \"Mais\"]\n",
    "\n",
    "TEAM_SIZES = {\"Bipbip\": [(2048, 1536), 8],\n",
    "              \"Pead\": [(3328, 2496), 13],\n",
    "              \"Roseau\": [(1280, 960), 5],\n",
    "              \"Weedelec\": [(5120, 3840), 20]}\n",
    "\n",
    "TARGET_SIZES = {\"Bipbip\": (1536, 2048, 4),\n",
    "                \"Pead\": (2464, 3280, 4),\n",
    "                \"Roseau\": (820, 1227, 4),\n",
    "                \"Weedelec\": (3456, 5184, 4)}\n",
    "\n",
    "\n",
    "#------------- scegli TEAM/CROP e se portare a target -----------\n",
    "toTarget = True\n",
    "standard_dim = False\n",
    "team = teams[1] # --> TEAM\n",
    "crop = crops[0] # --> CROP\n",
    "\n",
    "scale = LUT_scale[team + crop]\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "filenames = os.listdir(os.path.join(dataset_dir, team, crop, 'Images'))\n",
    "filenames = [f.split('.')[0] for f in filenames]\n",
    "\n",
    "curr_filename = filenames[item]\n",
    "item+=1\n",
    "\n",
    "#--------------- immagine a patch -------------------------------------------------------------------------\n",
    "    \n",
    "if os.path.isfile(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.png')):\n",
    "    image = preprocess_input(np.array(Image.open(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.png')).resize(TEAM_SIZES[team][0])))\n",
    "else:\n",
    "    image = preprocess_input(np.array(Image.open(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.jpg')).resize(TEAM_SIZES[team][0])))\n",
    "\n",
    "mask = np.array(Image.open(os.path.join(dataset_dir, team, crop, 'Masks', curr_filename + '.png')).resize(TEAM_SIZES[team][0]))\n",
    "\n",
    "out_sigmoid = np.zeros((1, img_h*int(TEAM_SIZES[team][1]/scale), img_w*int(TEAM_SIZES[team][1]/scale), 4))\n",
    "\n",
    "# predico ogni patch e la posiziono nella parte rispettiva di out_sigmoid\n",
    "for i in range(int(TEAM_SIZES[team][1]/scale)):\n",
    "    for j in range(int(TEAM_SIZES[team][1]/scale)):\n",
    "        patch = resize_target(image[i*scale*img_h:(i+1)*scale*img_h,j*scale*img_w:(j+1)*scale*img_w,:], (img_h, img_w, 3))\n",
    "        out_sigmoid[0, i*img_h:(i+1)*img_h,j*img_w:(j+1)*img_w,:] = model.predict(x = tf.expand_dims(patch,0))[0]\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# lascio separato [1, 0, 0, 0] da [0, 1, 0, 0] per visualizzare differenza\n",
    "prediction = tf.argmax(out_sigmoid, -1)[0, ...].numpy()\n",
    "\n",
    "if toTarget:\n",
    "    zoom = tf.argmax(resize_target(out_sigmoid[0, ...], TARGET_SIZES[team]), -1).numpy()\n",
    "    # unisco orange a background\n",
    "    zoom[np.where(zoom == 1)] = 0 \n",
    "\n",
    "# colori per visualizzare\n",
    "LUT = [[0, 0, 0],\n",
    "       [254, 124, 18],\n",
    "       [255, 255, 255],\n",
    "       [255, 0, 0]]\n",
    "    \n",
    "prediction_img = np.zeros([prediction.shape[0], prediction.shape[1], 3])\n",
    "zoomed_img = np.zeros([zoom.shape[0], zoom.shape[1], 3])\n",
    "\n",
    "#-------------- predizione --------------------------------------------------\n",
    "for i in range(0, N_classes):\n",
    "    prediction_img[np.where(prediction == i)] = LUT[i]\n",
    "#------------ predizione zummata ---------------------------------------------\n",
    "if toTarget:\n",
    "    for i in range(0, N_classes):\n",
    "        zoomed_img[np.where(zoom == i)] = LUT[i]\n",
    "        \n",
    "ax[0].imshow(np.uint8(image))\n",
    "ax[1].imshow(np.uint8(mask))\n",
    "ax[2].imshow(np.uint8(prediction_img))\n",
    "if toTarget:\n",
    "    ax[3].imshow(np.uint8(zoomed_img))\n",
    "\n",
    "fig.canvas.draw()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------------- faccio predizioni e preparo submission --------------------------\n",
    "import json\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#---------------- encode function ------------------------------------------\n",
    "def rle_encode(img):\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "#---------------- prepare submission ---------------------------------------\n",
    "def prepare_img(dataset_dir, team, crop, curr_filename, TEAM_SIZES, TARGET_SIZES, scale, preprocess_input):\n",
    "    if os.path.isfile(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.png')):\n",
    "        image = preprocess_input(np.array(Image.open(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.png')).resize(TEAM_SIZES[team][0])))\n",
    "    else:\n",
    "        image = preprocess_input(np.array(Image.open(os.path.join(dataset_dir, team, crop, 'Images', curr_filename + '.jpg')).resize(TEAM_SIZES[team][0])))\n",
    "\n",
    "    out_sigmoid = np.zeros((1, img_h*int(TEAM_SIZES[team][1]/scale), img_w*int(TEAM_SIZES[team][1]/scale), 4))\n",
    "\n",
    "    for i in range(int(TEAM_SIZES[team][1]/scale)):\n",
    "        for j in range(int(TEAM_SIZES[team][1]/scale)):\n",
    "            patch = resize_target(image[i*scale*img_h:(i+1)*scale*img_h,j*scale*img_w:(j+1)*scale*img_w,:], (img_h, img_w, 3))\n",
    "            out_sigmoid[0, i*img_h:(i+1)*img_h,j*img_w:(j+1)*img_w,:] = model.predict(x = tf.expand_dims(patch,0))[0]\n",
    "\n",
    "    return out_sigmoid\n",
    "#----------------------------------------------------------------------------       \n",
    "    \n",
    "#-------- dati --------------------------------------------------\n",
    "teams = [\"Bipbip\", \"Pead\", \"Roseau\", \"Weedelec\"]\n",
    "crops = [\"Haricot\", \"Mais\"]\n",
    "\n",
    "TARGET_SIZES = {\"Bipbip\": (1536, 2048, 4),\n",
    "                \"Pead\": (2464, 3280, 4),\n",
    "                \"Roseau\": (820, 1227, 4),\n",
    "                \"Weedelec\": (3456, 5184, 4)}\n",
    "\n",
    "dataset_dir = os.path.join(cwd,'Development_Dataset', 'Test_Dev')\n",
    "prediction_dir = os.path.join(cwd, 'predictions')\n",
    "\n",
    "\n",
    "#------------ predizioni per Test set ----------------------------\n",
    "submission_dict = {}\n",
    "for team in teams:\n",
    "    print(team)\n",
    "    for crop in crops:\n",
    "        print(crop)\n",
    "        # aggiorna la scala a seconda di TEAM e CROP\n",
    "        scale = LUT_scale[team + crop]\n",
    "        imm_source = os.path.join(dataset_dir, team, crop, 'Images')\n",
    "        filenames = os.listdir(imm_source)\n",
    "        filenames = [f.split('.')[0] for f in filenames]\n",
    "        \n",
    "        for curr_filename in filenames:\n",
    "            print(curr_filename)\n",
    "            #preprocessing\n",
    "            out_sigmoid = prepare_img(dataset_dir, team, crop, curr_filename, TEAM_SIZES, TARGET_SIZES, scale, preprocess_input)  \n",
    "            \n",
    "            predicted_class = tf.argmax(resize_target(out_sigmoid[0, ...], TARGET_SIZES[team]), -1).numpy()\n",
    "            #riporto le calssi standard per usare rle_encode senza modificarlo (potevo cambiare indici anche li)\n",
    "            predicted_class[np.where(predicted_class == 1)] = 0\n",
    "            predicted_class[np.where(predicted_class == 2)] = 1\n",
    "            predicted_class[np.where(predicted_class == 3)] = 2\n",
    "            \n",
    "            # costruisco il dict\n",
    "            submission_dict[curr_filename] = {}\n",
    "            submission_dict[curr_filename]['shape'] = [TARGET_SIZES[team][0], TARGET_SIZES[team][1]]\n",
    "            submission_dict[curr_filename]['team'] = team\n",
    "            submission_dict[curr_filename]['crop'] = crop\n",
    "            submission_dict[curr_filename]['segmentation'] = {}\n",
    "            \n",
    "            # distinguo tra crop e weed\n",
    "            rle_encoded_crop = rle_encode(predicted_class == 1) # crop\n",
    "            rle_encoded_weed = rle_encode(predicted_class == 2) # weed\n",
    "            \n",
    "            # trascrivo rle_encoded_crop e rle_encoded_weed\n",
    "            submission_dict[curr_filename]['segmentation']['crop'] = rle_encoded_crop\n",
    "            submission_dict[curr_filename]['segmentation']['weed'] = rle_encoded_weed\n",
    "\n",
    "# salvo predictions in json\n",
    "if not os.path.exists(prediction_dir):\n",
    "        os.makedirs(prediction_dir)\n",
    "with open(os.path.join(prediction_dir,'submission.json'), 'a+') as f:\n",
    "    json.dump(submission_dict, f)\n",
    "print(\"predictions saved\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multiclass_Segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
